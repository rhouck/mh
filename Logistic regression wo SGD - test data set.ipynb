{
 "metadata": {
  "name": "",
  "signature": "sha256:ba469ba4a9682a7832fab6da956ca95a32cb604101c3b5c8a39f913f5098f1a7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# load source data\n",
      "# index records by auction_id\n",
      "data = pd.read_csv('source/20140129.0.click.0.csv', index_col=2)\n",
      "click = pd.DataFrame(data)\n",
      "\n",
      "data = pd.read_csv('source/20140129.0.view.0.csv', index_col=2)\n",
      "view = pd.DataFrame(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 357
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert unix timestamps to datetime\n",
      "for i in ['event_time','request_time', 'view_time']:\n",
      "    view[i] = pd.to_datetime(view[i]/1000000, unit='s')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 358
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add new column to view data signifiying whether an ad was clicked or not\n",
      "# initialize feature as zeros\n",
      "view['clicked'] = 0\n",
      "\n",
      "# select any click column and rename it to join with view dataframe\n",
      "click_series = click['event_type']\n",
      "click_series.name = 'event_type_click'\n",
      "\n",
      "# change clicked ad rows 'clicked' value to 1\n",
      "matched = view.join(click_series, how='inner')\n",
      "view.loc[matched.index, 'clicked'] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 359
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# isolate columns that can be manipulated to affect CTR\n",
      "# ignore line item id\n",
      "# ignore url - assuming there are too many to make sense of, especially considering how few rows are available\n",
      "# ignore georgraphy\n",
      "# ignore time / day of week\n",
      "cols = ['clicked',\n",
      "        'creative_id', \n",
      "        'universal_site_id', \n",
      "        'adx_page_categories', \n",
      "        'matching_targeted_keywords', \n",
      "        'exchange', \n",
      "        'ad_position', \n",
      "        'matching_targeted_segments', \n",
      "        'device_type'\n",
      "        ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 360
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# drop universal site id when adx_page_categories is supplied"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 361
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test insertion order as only explanatory column"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 362
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this function returns a sparce matrix containing hashed feature:value pairs for each feature vector (row)\n",
      "# with online (iterative) learning, it's impossible to know the full range of categorical values for a feature ahead of time\n",
      "# to get around this, we create new features for each unique feature:value pairs by storing hashed values to represent indices in a large vector\n",
      "\n",
      "from sklearn.feature_extraction import FeatureHasher\n",
      "\n",
      "# this is the hashing algorithm we'll be using to map the feature set of unknown complexity\n",
      "hasher = FeatureHasher(input_type='string', n_features=(2 ** 15))\n",
      "\n",
      "def hash_row(raw_x, hasher):\n",
      "    x = []\n",
      "    for count, value in enumerate(raw_x):\n",
      "        if isinstance(value, str):    \n",
      "            vals = value.split()\n",
      "            for v in vals:\n",
      "                x.append('F%s:%s' % (count,v))\n",
      "            continue\n",
      "        if  np.isnan(value):\n",
      "            continue\n",
      "        if value:\n",
      "            x.append('F%s:%s' % (count,value))\n",
      "    \n",
      "    x = hasher.transform([x])\n",
      "    return x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime\n",
      "\n",
      "# convert data set to bank array of sparce matrices\n",
      "for t, i in enumerate(view.index):\n",
      "        \n",
      "    # add new row to bank\n",
      "    y = view.ix[i][cols[0]]\n",
      "    raw_x = view.ix[i][cols[1:]]\n",
      "    \n",
      "    row = [y, hash_row(raw_x, hasher)]\n",
      "    \n",
      "    # create bank to store hashed rows\n",
      "    # store recent indexes to drop from data frame in batches\n",
      "    if t == 0:\n",
      "        hashed_rows = [row]\n",
      "        ind_bank = [i]\n",
      "    else:\n",
      "        hashed_rows.append(row)\n",
      "        ind_bank.append(i)\n",
      "    \n",
      "    # monitor progress\n",
      "    if t % 20000 == 0 and t > 0:   \n",
      "        \n",
      "        # drop rows from data frame\n",
      "        view = view.drop(ind_bank)\n",
      "        ind_bank = []   \n",
      "        print '%s\\trows processed: %d' % (datetime.datetime.now(), t)\n",
      "\n",
      "view = view.drop(ind_bank)\n",
      "print \"Finished converting to sparse matrices\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-12-07 17:17:19.957504\trows processed: 20000\n",
        "2014-12-07 17:17:37.194324\trows processed: 40000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:17:57.219104\trows processed: 60000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:18:14.187423\trows processed: 80000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:18:30.633260\trows processed: 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:18:47.407559\trows processed: 120000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:19:04.188097\trows processed: 140000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:19:24.791562\trows processed: 160000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:19:42.169158\trows processed: 180000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:20:01.435362\trows processed: 200000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:20:17.873033\trows processed: 220000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:20:34.817806\trows processed: 240000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:20:52.229351\trows processed: 260000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:21:09.635472\trows processed: 280000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:21:27.866332\trows processed: 300000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:21:45.545265\trows processed: 320000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:22:04.930142\trows processed: 340000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:22:21.718235\trows processed: 360000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:22:39.094262\trows processed: 380000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:22:56.011066\trows processed: 400000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:23:13.573909\trows processed: 420000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:23:30.204033\trows processed: 440000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:23:48.662434\trows processed: 460000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:24:06.277274\trows processed: 480000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:24:22.583225\trows processed: 500000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished converting to sparse matrices"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 364
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp_hashed_rows = hashed_rows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 365
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert hashed_rows to numpy array\n",
      "t = 0\n",
      "temp = []\n",
      "while hashed_rows:\n",
      "    \n",
      "    temp.append(hashed_rows.pop())   \n",
      "\n",
      "    if t % 20000 == 0 and t > 0:     \n",
      "        \n",
      "        try:\n",
      "            bank = np.append(bank, temp, axis=0)\n",
      "        except:\n",
      "            bank = np.asarray(temp)\n",
      "        temp = []\n",
      "        \n",
      "        print '%s\\trows processed: %d' % (datetime.datetime.now(), t)\n",
      "        \n",
      "    t += 1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-12-07 17:28:23.237779\trows processed: 20000\n",
        "2014-12-07 17:29:05.913413\trows processed: 40000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:19.278212\trows processed: 60000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:19.542012\trows processed: 80000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:19.798780\trows processed: 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:20.740466\trows processed: 120000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:20.948087\trows processed: 140000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:21.510425\trows processed: 160000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:21.718391\trows processed: 180000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:21.911322\trows processed: 200000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:22.449090\trows processed: 220000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:22.604528\trows processed: 240000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:26.146225\trows processed: 260000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:26.326006\trows processed: 280000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:26.502577\trows processed: 300000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:26.680035\trows processed: 320000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:26.844726\trows processed: 340000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:27.003743\trows processed: 360000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:27.338395\trows processed: 380000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:27.511617\trows processed: 400000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:27.680742\trows processed: 420000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:27.847325\trows processed: 440000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:28.016985\trows processed: 460000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:28.185606\trows processed: 480000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-12-07 17:29:28.350550\trows processed: 500000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 366
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 369,
       "text": [
        "array([[0,\n",
        "        <1x32768 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 9 stored elements in Compressed Sparse Row format>],\n",
        "       [0,\n",
        "        <1x32768 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 8 stored elements in Compressed Sparse Row format>],\n",
        "       [0,\n",
        "        <1x32768 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 8 stored elements in Compressed Sparse Row format>]], dtype=object)"
       ]
      }
     ],
     "prompt_number": 369
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm, grid_search, datasets, cross_validation\n",
      "\n",
      "iris = datasets.load_iris()\n",
      "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "svr = svm.SVC()\n",
      "skf = cross_validation.StratifiedKFold(y, n_folds=2)\n",
      "clf = grid_search.GridSearchCV(svr, parameters)\n",
      "clf.fit(iris.data, iris.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "object of type 'numpy.int64' has no len()",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-271-602a27f80226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rbf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msvr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/ryanchouck/Desktop/dev/mh/venv/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, y, n_folds, indices, shuffle, random_state)\u001b[0m\n\u001b[1;32m    400\u001b[0m                  random_state=None):\n\u001b[1;32m    401\u001b[0m         super(StratifiedKFold, self).__init__(\n\u001b[0;32m--> 402\u001b[0;31m             len(y), n_folds, indices, shuffle, random_state)\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
       ]
      }
     ],
     "prompt_number": 271
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "clf = LogisticRegression()\n",
      "clf.fit(bank[:,1], bank[:,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "The number of classes has to be greater than one.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-174-9c2cd6982267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbank\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbank\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Users/ryanchouck/Desktop/dev/mh/venv/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0my_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             raise ValueError(\"The number of classes has to be greater than\"\n\u001b[0m\u001b[1;32m    677\u001b[0m                              \" one.\")\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one."
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 249,
       "text": [
        "(8339, 67)"
       ]
      }
     ],
     "prompt_number": 249
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 246,
       "text": [
        "array([ <1x32768 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 7 stored elements in Compressed Sparse Row format>,\n",
        "       <1x32768 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 10 stored elements in Compressed Sparse Row format>], dtype=object)"
       ]
      }
     ],
     "prompt_number": 246
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "# implement simple grid search to find best hyper-parameters\n",
      "Cs = np.array([.01, .1, 1, 10,])\n",
      "Dims = np.array([1, 10, 100, 200, None])\n",
      "for c in Cs:\n",
      "    for d in Dims:\n",
      "        print \"C: %s, Dimensions: %s\" % (c, d)\n",
      "        model = Model(Xs, ys, LogisticRegression(C=c), components=d)\n",
      "        scores = model.iter_cross_val(classification=True)\n",
      "        print \"accuracy score: %s, log_loss: %s\" % (scores['accuracy_score'] ,scores['log_loss'])\n",
      "        print \"\"\n",
      "\n",
      "        # test fitted model on new data\n",
      "model = Model(Xs, ys, LogisticRegression(C=1))\n",
      "model.model.fit(model.Xs, ys)\n",
      "test_classifier(model, test_set, y_col, X_cols)\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print view.shape\n",
      "name = view.ix[0].name\n",
      "#r = view.pop(view.ix[0])\n",
      "print view.shape\n",
      "#print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(518340, 67)\n",
        "(518340, 67)\n"
       ]
      }
     ],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print view.shape\n",
      "view = view.drop(name)\n",
      "print view.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(518340, 67)\n",
        "(518339, 67)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}